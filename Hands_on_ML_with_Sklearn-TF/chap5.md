# 第五章 支持向量机

支持向量机（*Support Vector Machine*, SVM）是一种非常强大而多功能的机器学习莫衷，能实现线性和非线性分类、回归甚至异常值检测。它是机器学习中最流行的模型之一，凡是对机器学习感兴趣的人都必备的工具。 SVM 尤其适合小型或中型数据集的复杂分类问题。

本章会解释 SVM 的核心准则，以及如何使用它们，它们是如何工作的。

## 线性支持向量机分类

SVM 的基本思路可以用这些图片来很好地解释。图5-1展示了部分鸢尾花数据集，在第四章中有所介绍。这两类很容易用一条直线来划分（它们是线性可分的）。左图展示了三种线性分类器的决策边界。虚线所表示的模型表现过差，甚至没能合适地把两类分开。其余的两个模型在训练集上表现优秀，但是它们的决策边界离实例太近了，在新实例上可能不会表现很好。相比之下，右图中的实线代表 SVM 分类器的决策边界，它不仅划分了两个类别，而且离最近的实例尽可能的远。你可以认为 SVM 在两类之间保持了最宽通道（以平行虚线表示）。这被称为**大间隔分类**（*large margin classification*）。

![1](./images/chap5/5-1.png)

注意，添加通道外的训练实例完全不会影响决策边界：它是由通道边缘的实例决定（或“支持”）的。这些实例被称为支持向量（图 5-1 中的圆圈）。

> **警告**
> SVM 对特征缩放比较敏感，你可以在图 5-2 中看到：在左图，垂直的比例比水平的比例大得多，所以最宽通道接近水平。在特征缩放之后（比如使用 Scikit-Learn 的`StandardScaler`），决策边界看起来就好多了（右图）。

![2](./images/chap5/5-2.png)

### 软间隔分类

如果我们严格规定所有的实例都在通道外，且都在右侧，这被称为**硬间隔分类**（*hard margin classification*）。它有两个主要问题，第一，只有当数据线性可分时，它才能工作；第二，它对异常值过于敏感。图 5-3 展示了加了一个异常值的鸢尾花数据集：左图中，不可能找到一个硬间隔；右图中，决策边界和图 5-1 中没有异常值的决策边界差异过大，可能不会泛化得很好。

![3](./images/chap5/5-3.png)

为了避免这些情况发生，最好使用更灵活的模型。目标是在两者之间找到平衡：保持通道尽可能大和限制间隔违规（*margin violations*）（即实例在通道中间，或者在错误的一侧）。这被称为**软间隔分类**（*soft margin classification*）。

在 Scikit-Learn 中的 SVM 类中，你可以使用超参数`C`来控制平衡：小的`C`值会有更宽的通道，但是间隔违规也会
