# 第十六章：强化学习

**强化学习**（*Reinforcement	Learning*，RL）是当今机器学习中最令人兴奋的领域之一，也是最古老的领域之一。它在 20 世纪 50 年代就开始了，多年来产生了许多有趣的应用，尤其是在游戏方面（比如， *TD-Gammon* ，一种双陆棋游戏程序）和机器控制方面，不过很少有能上头条新闻的。但是， 在 2013 年发生了一场革命，来自英国新兴公司 DeepMind 的研究者 [演示了一个能够游玩任何雅达利游戏的系统](https://goo.gl/hceDs5) ，甚至能 [超过大多数人类](https://goo.gl/hgpvz7) ，它只用了很少的像素作为输入，对游戏规则也一无所知。这是一系列令人惊叹的壮举中的第一次，在 2016 年 3 月以 AlphaGo 击败世界围棋冠军李世石而达到高潮。从未有程序能击败围棋领域的大师，更别说是世界冠军了。如今，强化学习的整个领域正在酝酿着新的想法，具有广泛的应用范围。DeepMind 在 2014 年已被谷歌以超过 5 亿的价格收购。

所以他们是怎么办到的？事后看来，它看起来相当简单：他们将深度学习的力量应用于强化学习的领域，而它超越了他们最狂野的梦想。本章中，我们首先会解释强化学习是什么，它擅长什么，之后我们会展示深度强化学习中两种最重要的技术：**策略梯度**（*policy gradients*）和**深度Q-网络**（*Q-networks*，DQN），包括**马尔可夫决策过程**（*Markov decision processes*，MDP）的讨论。我们会使用这些技术来训练一个模型来平衡移动推车上的杆子，另一个模型来游玩雅达利游戏。同样的技术也能用于各种各样的任务，从步行机器人到自动驾驶汽车。
