# 第十三章：卷积神经网络

尽管在 1996 年， IBM 的超级计算机深蓝击败了世界国际象棋冠军 Garry	Kasparov ，但是直到现在计算机都不能可靠地解决一些琐碎复杂的任务，比如检测照片中的小狗，或是语音识别。为什么这些任务对于人类而言不费吹灰之力？答案是感知发生在我们意识到的领域之外，在专门化的视觉、听觉以及大脑中的其他感知模块中。当感知信息达到意识层时，它已经被高级特征所装饰。例如，当你看一张可爱的小狗照片时，你不能选择*不*去看这只小狗，或者*不*去注意它的可爱。你也不能解释你是*如何*认出这是一只可爱的小狗，这对你而言是显而易见的。因此，我们不能相信自己的主观经验：感知并不是无关紧要的，为了理解它，我们必须研究感知模块是如何工作的。

卷积神经网络（CNN）是从大脑视觉皮层的研究中出现的，自从 20 世纪 80 年代以来，它们一直被用于图像识别。在近几年，多亏计算能力的进步、可用训练数据的数量的增加以及训练深度网络的技巧的提升， CNN 致力于在一些复杂视觉任务上获得超人的表现。它们强化了图像搜索服务、无人驾驶汽车、自动视频分类等领域。此外， CNN 并不局限于视觉感知：它们在其他任务中也很成功，比如语音识别或自然语言处理（*natural	language	processing*，NLP）。不过，我们现在专注于视觉应用。

在本章中，我们会介绍 CNN 的由来，构建模块的外观，以及如何用 Tensorflow 实现它们。之后我们会展示一些最佳的 CNN 架构。

## 视觉皮层的架构

在 1958 年 和 1959 年， David H. Hubel 和 Torsten Wiesel 进行了一系列对猫的实验（几年后是对猴子的实验），在视觉皮层的结构上给出了重要的见解（作者因此获得了 1981 年的诺贝尔生理和医学奖）。特别地，他们展示了视觉皮层中许多神经元都有一个微小的**局部感受野**（*local receptive field*），意味着它们只对视野中有限区域内的视觉刺激有反应（见图 13-1 ， 5 个神经元的局部感受野用虚线圆圈表示）。不同神经元的感受野可能会重叠，它们一起铺满了整个视觉域。此外，作者也展示了一些神经元只对水平方向的图像有反应，而另一些只对不同方向上的图像有反应（两个神经元也许会有相同的感受野，但是对不同方向的图像做出反应）。他们也注意到，有些神经元有更大的感受野，它们会对更复杂的图案——低级图案的组合——做出反应。这些观测结果引发了猜想，高级神经元基于邻近低级神经元的输出（在图 13-1 中，注意每个神经元只从前一层上连接了部分神经元）。这个强大的架构可以在视野中任何地方检测各种复杂模图案。

![1](./images/chap13/13-1.png)

这些视觉皮层的研究启发了 1980 年的 [新认知机](http://www.cs.princeton.edu/courses/archive/spr08/cos598B/Readings/Fukushima1980.pdf)  ，逐渐演变为我们现在称呼的**卷积神经网络**（*convolutional neural networks*）。一个重要的里程碑是 1998 年 由 Yann	LeCun,	Léon	Bottou,	Yoshua	Bengio,	and	Patrick	Haffner 发表的 [论文](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf) ，提出了著名的 *LeNet-5* 架构，被广泛运用于手写支票号码识别。这个架构有一些你已知的构建模块，比如全连接层和 sigmoid 激励函数，不过也介绍了两个全新的构建模块：**卷积层**（*convolutional layers*）和**池化层**（*pooling layers*）。现在让我们来看一看。

> **笔记**
> 对于图像识别任务，为什么不简单使用一个拥有全连接层的常规深度神经网络？不幸的是，尽管这样在小型图片（比如 MNIST ）上运行良好，但是，它在大型图片上就会由于需求参数过多而崩溃。例如，一张 100×100 的图片有 10000 个像素，如果第一层有 1000 个神经元（这已经严重限制了传输到下一层的信息量），这就意味着一共有 1000 万条连接。这还只是第一层。 CNN 使用局部连接层解决这个问题。

## 卷积层

CNN 中最重要的构建模块就是卷积层（*convolutional layer*）：第一卷积层的神经元不是连接到输入图像的每个像素上（就像上一章），而是只连接到感受野上的像素（见图 13-2 ）。依次，第二卷积层中的每个神经元也只连接位于第一卷积层小矩形内的神经元。这种架构允许网络专注于第一隐藏层中的低级特征，然后将它们组合为下一隐藏层中的高级特征，以此类推。这种层次结构在现实世界的图像中很常见，这也是 CNN 在图像识别上表现优异的原因。

![2](./images/chap13/13-2.png)

> **笔记**
> 直到现在，所有我们看到的多层神经网络都有由一长串神经元组成的层，我们不得不将输入图像压缩为一维
